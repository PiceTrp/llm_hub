{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7bbfafa-c93a-49b0-bd1e-e9fc3cb3318b",
   "metadata": {},
   "source": [
    "YT: https://www.youtube.com/watch?v=sVcwVQRHIc8&t=3s <br>\n",
    "code: https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_1_to_4.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "00ab1597-d90a-4759-a984-a8e800b91450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup langsmith\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    # load environment variables from .env file (requires `python-dotenv`)\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "if \"LANGSMITH_API_KEY\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\n",
    "        prompt=\"Enter your LangSmith API key (optional): \"\n",
    "    )\n",
    "if \"LANGSMITH_PROJECT\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_PROJECT\"] = getpass.getpass(\n",
    "        prompt='Enter your LangSmith Project Name (default = \"default\"): '\n",
    "    )\n",
    "    if not os.environ.get(\"LANGSMITH_PROJECT\"):\n",
    "        os.environ[\"LANGSMITH_PROJECT\"] = \"default\"\n",
    "# if \"OPENAI_API_KEY\" not in os.environ:\n",
    "#     os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\n",
    "#         prompt=\"Enter your OpenAI API key (required if using OpenAI): \"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "743b4a5e-f972-4a33-8807-58a8541c2a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"../serious-hold-453009-g1-eff08c861e11.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c721705-1ab0-45de-8504-fe5fcb84f6f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rag-101'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"LANGSMITH_PROJECT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "668825b1-94e0-4631-b26c-88d33d015fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensure your VertexAI credentials are configured\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.0-flash-001\", model_provider=\"google_vertexai\")\n",
    "embeddings = VertexAIEmbeddings(model=\"text-embedding-004\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed47bd5-259a-4004-a697-af37b4cad97a",
   "metadata": {},
   "source": [
    "# Get started RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5f88b8-dc1a-421d-804f-ed8662cfe615",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9032ac2-8aba-4da6-8fb3-1ae49c7e18b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1937d96-ce14-46d8-8839-00f170d50373",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### INDEXING ####\n",
    "\n",
    "# Load Documents\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6429cdee-5180-4ce9-adfd-f42ef45f6917",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Embed\n",
    "vectorstore = Chroma.from_documents(documents=splits, \n",
    "                                    embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a4f1fd6f-05b4-46d5-a62d-5e036f26515c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents in vectorstore: 66\n",
      "Available keys: dict_keys(['ids', 'embeddings', 'documents', 'uris', 'data', 'metadatas', 'included'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>metadata_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ffa41241-b0a9-4339-a545-548e6206220c</td>\n",
       "      <td>LLM Powered Autonomous Agents\\n    \\nDate: Jun...</td>\n",
       "      <td>https://lilianweng.github.io/posts/2023-06-23-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eba019db-8810-44f2-8bc8-74253b23b4b6</td>\n",
       "      <td>Memory\\n\\nShort-term memory: I would consider ...</td>\n",
       "      <td>https://lilianweng.github.io/posts/2023-06-23-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b6bbeb31-f03f-43b6-a54a-1f1b268b9a20</td>\n",
       "      <td>Fig. 1. Overview of a LLM-powered autonomous a...</td>\n",
       "      <td>https://lilianweng.github.io/posts/2023-06-23-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c6de9c76-0a58-42e1-9e9c-00aeb96c9ede</td>\n",
       "      <td>Tree of Thoughts (Yao et al. 2023) extends CoT...</td>\n",
       "      <td>https://lilianweng.github.io/posts/2023-06-23-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8135ced6-a8ef-44a0-8baf-003f5cd6b864</td>\n",
       "      <td>Another quite distinct approach, LLM+P (Liu et...</td>\n",
       "      <td>https://lilianweng.github.io/posts/2023-06-23-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  ffa41241-b0a9-4339-a545-548e6206220c   \n",
       "1  eba019db-8810-44f2-8bc8-74253b23b4b6   \n",
       "2  b6bbeb31-f03f-43b6-a54a-1f1b268b9a20   \n",
       "3  c6de9c76-0a58-42e1-9e9c-00aeb96c9ede   \n",
       "4  8135ced6-a8ef-44a0-8baf-003f5cd6b864   \n",
       "\n",
       "                                            document  \\\n",
       "0  LLM Powered Autonomous Agents\\n    \\nDate: Jun...   \n",
       "1  Memory\\n\\nShort-term memory: I would consider ...   \n",
       "2  Fig. 1. Overview of a LLM-powered autonomous a...   \n",
       "3  Tree of Thoughts (Yao et al. 2023) extends CoT...   \n",
       "4  Another quite distinct approach, LLM+P (Liu et...   \n",
       "\n",
       "                                     metadata_source  \n",
       "0  https://lilianweng.github.io/posts/2023-06-23-...  \n",
       "1  https://lilianweng.github.io/posts/2023-06-23-...  \n",
       "2  https://lilianweng.github.io/posts/2023-06-23-...  \n",
       "3  https://lilianweng.github.io/posts/2023-06-23-...  \n",
       "4  https://lilianweng.github.io/posts/2023-06-23-...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def inspect_chroma_vectorstore(vectorstore):\n",
    "    \"\"\"\n",
    "    Display information about documents stored in a Chroma vectorstore.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    count = vectorstore._collection.count()\n",
    "    print(f\"Total documents in vectorstore: {count}\")\n",
    "    \n",
    "    vectorstore_data = vectorstore._collection.get()\n",
    "    print(f\"Available keys: {vectorstore_data.keys()}\")\n",
    "    \n",
    "    data = {\n",
    "        \"id\": vectorstore_data['ids'],\n",
    "        \"document\": vectorstore_data['documents'],\n",
    "    }\n",
    "    \n",
    "    # Add metadata if available\n",
    "    if 'metadatas' in vectorstore_data and vectorstore_data['metadatas']:\n",
    "        for key in vectorstore_data['metadatas'][0].keys():\n",
    "            data[f\"metadata_{key}\"] = [m.get(key) for m in vectorstore_data['metadatas']]\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "df = inspect_chroma_vectorstore(vectorstore)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a1197389-014b-488c-8ee2-04320933a326",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['context', 'question']\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "display(prompt)\n",
    "print()\n",
    "display(prompt.messages[0].prompt.template)\n",
    "print(prompt.input_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef0f07b9-2c6f-42f8-a732-c2a4c4f55a6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition is a method of breaking down complex tasks into smaller, more manageable steps. This can be achieved through prompting the model to \"think step by step\" or by using task-specific instructions. It can also be accomplished with human input.\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### RETRIEVAL and GENERATION ####\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Question\n",
    "rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "44818123-527a-4859-b517-e4757c9973ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HuggingGPT is a framework that uses ChatGPT as a task planner to select models available on the HuggingFace platform and summarize responses based on the execution results. The main components include task planning, instruction, and response generation. It uses LLM to parse user requests, guide task parsing, and provide summarized results.\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question\n",
    "rag_chain.invoke(\"Briefly describe the HuggingGPT and tell what are the main components to implement it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "30cb1152-df35-427d-8d39-8f7467d47124",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but the provided context does not contain information about vision transformers. Therefore, I cannot answer your question.\\n\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question\n",
    "rag_chain.invoke(\"What is vision transformer?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301c92cf-483f-42cf-8d0f-3fc98d941db8",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dde74fab-72f5-47d4-b28d-78573ae92e57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens used: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Documents\n",
    "question = \"What kinds of pets do I like?\"\n",
    "document = \"My favorite pet is a cat.\"\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "print(f\"Total tokens used: {num_tokens_from_string(question, 'cl100k_base')}\")\n",
    "\n",
    "query_result = embeddings.embed_query(question)\n",
    "document_result = embeddings.embed_query(document)\n",
    "len(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "638ca65a-0dc0-476b-8875-0f5c92567aad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(query_result).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e1452288-ba4c-4af2-bb61-c64bd02b3e21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.6704918572044731\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "similarity = cosine_similarity(query_result, document_result)\n",
    "print(\"Cosine Similarity:\", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebe6f48-3882-46bc-ad43-c6ded83b3b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_hub",
   "language": "python",
   "name": "llm_hub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
